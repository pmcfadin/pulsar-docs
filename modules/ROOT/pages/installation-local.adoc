= Local Luna Streaming installation

[sidebar]
Edit and keystroke and note writer comments.

This topic gets you up and running with Luna Streaming on local Kubernetes (K8s) instance.

If you want to install Luna Streaming on a cloud provider's Kubernetes environment, see:

* xref:installation-aks.adoc[]
* xref:installation-eks.adoc[]
* xref:installation-gke.adoc[]

TIP: Also available in followup topics are post-install steps for xref:quickstart-developers.adoc[].


== Introduction

In this quickstart for installs of Luna Streaming on your local *DEV* environment, we'll cover:

* Required supporting software including resource recommendations.
* Accessing the Helm charts that install Luna Streaming.
* Getting Luna Streaming up and running locally using the Helm chart repo.
* Making sure Luna Streaming is working as expected.

== Prerequisites

In your local environment the following tools are required for provisioning a Luna Streaming cluster:

* https://helm.sh/docs/intro/install/[Helm v3+]
* https://kubernetes.io/docs/tasks/tools/install-kubectl/[Kubectl]

As Luna Streaming deploys on a K8s cluster, one must be available to target for installation.
The K8s environment may be a local version running on your development machine, an on-premises self-hosted environment, or a managed cloud offering.

Luna Streaming works with the following versions of Kubernetes either standalone or via a cloud provider:

[sidebar]
Dev please verify this.

* 1.16
* 1.17
* 1.18
* 1.19
* 1.20

To verify your K8s server version:

[source,bash]
----
kubectl version
----

*Output*:

[source,json]
----
Client Version: version.Info{Major:"1", Minor:"20", GitVersion:"v1.20.3", GitCommit:"01849e73f3c86211f05533c2e807736e776fcf29", GitTreeState:"clean", BuildDate:"2021-02-18T12:10:55Z", GoVersion:"go1.15.8", Compiler:"gc", Platform:"darwin/amd64"}
Server Version: version.Info{Major:"1", Minor:"18", GitVersion:"v1.18.16", GitCommit:"7a98bb2b7c9112935387825f2fce1b7d40b76236", GitTreeState:"clean", BuildDate:"2021-02-17T11:52:32Z", GoVersion:"go1.13.15", Compiler:"gc", Platform:"linux/amd64"}
----

Your K8s server version is a combination of the `Major:` and `Minor:` key/value pairs following `Server Version:`, in the example above, `1.18`.

If you don't have a K8s cluster available, you can use https://developers.redhat.com/products/codeready-containers/overview[OpenShift CodeReady Containers] that run within a VM, or one of the following local versions that run within Docker:

* https://k3d.io/[K3D]
* https://minikube.sigs.k8s.io/docs/start/[Minikube]
* https://kind.sigs.k8s.io/[Kind]

The instructions in this section focus on the Docker container solutions above, but the general instructions should work for other environments as well.

=== Resource recommendations for local Kubernetes installations

[sidebar]
This is for K8ssandra. Dev please verify this.

We recommend a machine specification of *no less* than 16 gigs of RAM and 8 virtual processor cores (4 physical cores). You'll want to adjust your Docker resource preferences accordingly. For this quick start we're allocating 4 virtual processors and 8 gigs of RAM to the Docker environment.

TIP: See the documentation for your particular flavor of Docker for instructions on configuring resource limits.

The following Minikube example creates a K8s cluster running K8s version 1.18.16 with 4 virtual processor cores and 8 gigs of RAM:

[source,bash]
----
minikube start --cpus=4 --memory='8128m' --kubernetes-version=1.18.16
----

*Output*:

[source,bash]
----
üòÑ  minikube v1.17.1 on NextSTEP 3.5.1
‚ú®  Automatically selected the docker driver. Other choices: hyperkit, ssh
üëç  Starting control plane node Luna Streaming in cluster Luna Streaming
üî•  Creating docker container (CPUs=4, Memory=8128MB) ...
üê≥  Preparing Kubernetes v1.18.16 on Docker 20.10.2 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîé  Verifying Kubernetes components...
üåü  Enabled addons: storage-provisioner, default-storageclass
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
----

=== Verify your Kubernetes environment

To verify your Kubernetes environment:

. Verify that your K8s instance is up and running in the `READY` status:
+
[source,bash]
----
 kubectl get nodes
----
+
*Output*:
+
[source,bash]
----
 NAME        STATUS   ROLES    AGE   VERSION
 Luna Streaming   Ready    master   21m   v1.18.16
----

[#storage-classes]
=== Validate the available Kubernetes StorageClasses

[sidebar]
Dev please verify this. This is particular to K8ssandra but may be relevant for AS.

Your K8s instance *must* support a storage class with a `VOLUMEBINDINGMODE` of `WaitForFirstConsumer`.

To list the available K8s storage classes for your K8s instance:

[source,bash]
----
kubectl get storageclasses
----

*Output*:

[source,bash]
----
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE   ALLOWVOLUMEEXPANSION   AGE
standard (default)   k8s.io/minikube-hostpath   Delete          Immediate           false                  2m25s
----

If you don't have a storage class with a `VOLUMEBINDINGMODE` of `WaitForFirstConsumer` as in the Minikube example above, you can install the https://github.com/rancher/local-path-provisioner[Rancher Local Path Provisioner]:

[source,bash]
----
kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
----

*Output*:

[source,bash]
----
namespace/local-path-storage created
serviceaccount/local-path-provisioner-service-account created
clusterrole.rbac.authorization.k8s.io/local-path-provisioner-role created
clusterrolebinding.rbac.authorization.k8s.io/local-path-provisioner-bind created
deployment.apps/local-path-provisioner created
storageclass.storage.k8s.io/local-path created
configmap/local-path-config created
----

Rechecking the available storage classes, you should see that a new `local-path` storage class is available with the required `VOLUMEBINDINGMODE` of `WaitForFirstConsumer`:

[source,bash]
----
kubectl get storageclasses
----

*Output*:

[source,bash]
----
NAME                 PROVISIONER                RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE
local-path           rancher.io/local-path      Delete          WaitForFirstConsumer   false                  3s
standard (default)   k8s.io/minikube-hostpath   Delete          Immediate              false                  39s
----

== Configure the Luna Streaming Helm repository

Luna Streaming is delivered via a collection of Helm charts for easy installation, so once you've got a suitable K8s environment configured, you'll need to add the Luna Streaming Helm chart repositories.

To add the Luna Streaming helm chart repos:

[sidebar]
We need the helm repo add command. The original instructions just say "do a helm search".

. Install https://helm.sh/docs/intro/install/[Helm v3+] if you haven't already.
. Add the main Luna Streaming stable Helm chart repo:
+
[source,bash]
----
 helm repo add Luna Streaming https://helm.Luna Streaming.io/stable
----

. If you want to access Luna Streaming services from outside of the Kubernetes cluster, also add the Traefik Ingress repo:
+
[source,bash]
----
 helm repo add traefik https://helm.traefik.io/traefik
----

. Finally, update your helm repository listing:
+
[source,bash]
----
 helm repo update
----

[sidebar]
Update the github repo.

TIP: Alternatively, you can download the individual charts directly from the project's https://github.com/Luna Streaming/Luna Streaming/releases[releases] page.

== Install Luna Streaming

The Luna Streaming helm charts make installation a snap.
You can override chart configurations during installation as necessary if you're an advanced user, or make changes after a default installation using `helm upgrade` at a later time.

[sidebar]
Dev please verify this.

Luna Streaming can install the following versions of Apache Pulsar:

* 2.7.x

IMPORTANT: Luna Streaming comes out of the box with a set of https://github.com/Luna Streaming/Luna Streaming/blob/main/charts/Luna Streaming/values.yaml[default values] tailored to getting up and running quickly.
Those defaults are intended to be a great starting point for smaller-scale local development but are *not* intended for production deployments.

To install a single node Luna Streaming cluster:

. Copy the following YAML to a file named `luna-streaming.yaml`:
+
[source,yaml]
----
Please include a complete and valid sample YAML file here.
----
+
That configuration file creates a Luna Streaming cluster with the following specifications:

 ** Please update with the specifications.

+
IMPORTANT: The `storageClass:` parameter must be a storage class with a `VOLUMEBINDINGMODE` of `WaitForFirstConsumer` as described in [Validate the available Kubernetes StorageClasses]({{< relref "#storage-classes" >}}).

. Use `helm install` to install Luna Streaming, pointing to the example configuration file using the `-f` flag:
+
[source,bash]
----
 helm install -f luna-streaming.yaml Luna Streaming Luna-Streaming/Luna-Streaming
----
+
*Output*:
+
[source,bash]
----
 NAME: Luna Streaming
 LAST DEPLOYED: Thu Feb 18 10:05:44 2021
 NAMESPACE: default
 STATUS: deployed
 REVISION: 1
----

== Verify your Luna Streaming installation

Depending upon your K8s configuration, initialization of your Luna Streaming installation can take a few minutes.
To check the status of your Luna Streaming deployment, use the `kubectl get pods` command:

[source,bash]
----
kubectl get pods
----

*Output*:

[source,bash]
----
NAME                                                  READY   STATUS     RESTARTS  AGE
prometheus-pulsar-kube-prometheus-sta-prometheus-0    2/2     Running    1         10m
pulsar-adminconsole-9669f6d98-dxjvp                   2/2     Running    3         12m
pulsar-autorecovery-7cf8d598d6-6fwpn                  1/1     Running    4         12m
pulsar-bastion-67776dddc-xc6tb                        1/1     Running    0         12m
pulsar-bookkeeper-0                                   1/1     Running    1         12m
pulsar-broker-7d9b8974dc-hd8xz                        1/1     Running    11        12m
pulsar-cert-manager-76c9d8d4d-szzh9                   1/1     Running    3         12m
pulsar-cert-manager-cainjector-dbff95bff-fbsmk        1/1     Running    5         12m
pulsar-cert-manager-webhook-8469dc9ff6-c5x29          1/1     Running    3         12m
pulsar-function-0                                     2/2     Running    0         12m
pulsar-grafana-6f7d749d86-bzgwb                       2/2     Running    0         12m
pulsar-kube-prometheus-sta-operator-c68c6bf4b-xrpdl   1/1     Running    0         12m
pulsar-kube-state-metrics-55fb767d74-ddqp4            1/1     Running    1         12m
pulsar-prometheus-node-exporter-cst5r                 1/1     Running    3         12m
pulsar-proxy-7685b58f69-jqpcl                         3/3     Running    4         12m
pulsar-pulsarheartbeat-5f897b5948-m4r7s               1/1     Running    2         12m
pulsar-zookeeper-0                                    1/1     Running    0         12m
pulsar-zookeeper-metadata-5l58k                       0/1     Completed  0         12m
----

The Luna Streaming pod in the example above is `pulsar-function-0`.

Verify the following:

* What do you need to verify?

Once all the pods are in the `Running` or `Completed` state, you can check the health of your Luna Streaming cluster.
There must be *no `PENDING` pods*.

To check the health of your Luna Streaming cluster:

. Do the following...
+
[source,bash]
----
 kubectl get ???
----
+
*Output*:
+
[source,bash]
----
 NAME   AGE
 dc1    51m
----

. Do the following:
+
[source,bash]
----
 kubectl describe CassandraDataCenter dc1 | grep "Cassandra Operator Progress:"
----
+
*Output*:
+
[source,bash]
----
    Cassandra Operator Progress:  Ready
----

. Do the following:
+
[source,bash]
----
 kubectl get services
----
+
*Output*:
+
[source,bash]
----
 NAME                                   TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                                                 AGE
 cass-operator-metrics                  ClusterIP   10.80.3.92     <none>        8383/TCP,8686/TCP                                       47m
 Luna Streaming-dc1-all-pods-service         ClusterIP   None           <none>        9042/TCP,8080/TCP,9103/TCP                              47m
 Luna Streaming-dc1-service                  ClusterIP   None           <none>        9042/TCP,9142/TCP,8080/TCP,9103/TCP,9160/TCP            47m
 Luna Streaming-dc1-stargate-service         ClusterIP   10.80.13.197   <none>        8080/TCP,8081/TCP,8082/TCP,8084/TCP,8085/TCP,9042/TCP   47m
 Luna Streaming-grafana                      ClusterIP   10.80.7.168    <none>        80/TCP                                                  47m
 Luna Streaming-kube-prometheus-operator     ClusterIP   10.80.8.109    <none>        443/TCP                                                 47m
 Luna Streaming-kube-prometheus-prometheus   ClusterIP   10.80.2.44     <none>        9090/TCP                                                47m
 Luna Streaming-reaper-reaper-service        ClusterIP   10.80.5.77     <none>        8080/TCP                                                47m
 Luna Streaming-seed-service                 ClusterIP   None           <none>        <none>                                                  47m
 kubernetes                             ClusterIP   10.80.0.1      <none>        443/TCP                                                 47m
 prometheus-operated                    ClusterIP   None           <none>        9090/TCP                                                47m
----
+
Do the following:

 ** {blank}+++<cluster-name>+++-+++<datacenter-name>+++-all-pods-service+++</datacenter-name>++++++</cluster-name>+++
 ** {blank}+++<cluster-name>+++-+++<datacenter-name>+++-dc1-service+++</datacenter-name>++++++</cluster-name>+++
 ** {blank}+++<cluster-name>+++-+++<datacenter-name>+++-stargate-service+++</datacenter-name>++++++</cluster-name>+++
 ** {blank}+++<cluster-name>+++-+++<datacenter-name>+++-seed-service+++</datacenter-name>++++++</cluster-name>+++

== Next steps

* xref:quickstart-developers.adoc[]

For configuration details specific to cloud providers, see:

* xref:installation-aks.adoc[]
* xref:installation-eks.adoc[]
* xref:installation-gke.adoc[]
